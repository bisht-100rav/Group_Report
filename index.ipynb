{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3e8d57",
   "metadata": {},
   "source": [
    "### Comparative Analysis of Cell Phone Detection Models: Single Shot MultiBox Detector (SSD), Faster R-CNN, and You Only Look Once (YOLO) Version 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee658568",
   "metadata": {},
   "source": [
    "<img src=\"images\\1.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7241a37a",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364b75f",
   "metadata": {},
   "source": [
    "*This project focuses on developing an accurate and efficient cell phone detection model using the YOLO (You Only Look Once) framework, in comparison with other models like Faster R-CNN and SSD RetinaNet. The objective is to contribute to computer vision advancements with practical applications in security, surveillance, and user experience enhancement. The project leverages the COCO 2017 and Google Open Images datasets for benchmarking and fine-tuning purposes.*\n",
    "\n",
    "*The key features of the project include harnessing YOLO's real-time capabilities for fast and efficient cell phone detection, utilizing the rich annotations of the COCO 2017 dataset, and comparing YOLO with other hub models like SSD RetinaNet and Faster R-CNN. Fine-tuning the YOLO model specifically for cell phone detection enhances its accuracy.*\n",
    "\n",
    "*One challenge is the computational power required by models like SSD RetinaNet and Faster R-CNN, which can slow down real-time detection. The project addresses this by optimizing YOLO for deployment on target hardware, ensuring real-time performance for practical applications.*\n",
    "\n",
    "*In summary, the project's approach involves developing and fine-tuning a YOLO-based cell phone detection system, benchmarking it against other models, and optimizing it for real-time deployment. The results aim to advance computer vision technology and provide effective solutions to real-world challenges.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69a69d",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17525438",
   "metadata": {},
   "source": [
    "The proliferation of cell phones has led to an increasing need for accurate and efficient methods of detecting these devices in various contexts. This project focuses on addressing this challenge through the exploration of cutting-edge computer vision techniques, specifically the YOLO (You Only Look Once) framework, alongside established models like Faster RCNN and SSD.\n",
    "\n",
    "The importance of this problem lies in its practical applications, ranging from enhancing security and surveillance systems to improving user experiences in public spaces. Detecting cell phones in complex real-world images is a task of paramount significance, as it contributes to the development of safer environments and more effective user interactions.\n",
    "\n",
    "Our aim is to develop a robust cell phone detection model capable of accurately identifying cell phones in diverse and intricate scenarios. We seek to harness the real-time capabilities of YOLO to achieve efficient and swift detection. To benchmark our model's performance, we utilize the COCO 2017 dataset, which offers comprehensive annotations and represents a wide array of scenarios.\n",
    "\n",
    "In summary, our project's objectives revolve around leveraging YOLO's potential for rapid cell phone detection, using a high-quality benchmark dataset, and ultimately contributing to the advancement of computer vision technology. Through the development of an accurate and efficient cell phone detection model, we aspire to make tangible contributions to security, surveillance, and user experience enhancement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142b60f",
   "metadata": {},
   "source": [
    "### Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56301e79",
   "metadata": {},
   "source": [
    "Akta&#351;, Y. &Ccedil;i&#287;dem. (2022, January 31). Object detection with Convolutional      Neural Networks. Medium. https://towardsdatascience.com/object-detection-with-convolutional-neural-networks-c9d729eedc18\n",
    "\n",
    "ArXiv.org e-print archive. (n.d.-a). https://arxiv.org/ftp/arxiv/papers/2204/2204.03371.pdf\n",
    "\n",
    "CVF Open Access. (n.d.-b). https://openaccess.thecvf.com/content_cvpr_2016_workshops/w3/papers/Le_Multiple_Scale_Faster-RCNN_CVPR_2016_paper.pdf\n",
    "\n",
    "Detecting driver cell-phone usage based on deep learning technique. (n.d.-c). https://hal.science/hal-03322926/document\n",
    "\n",
    "Detecting usage of mobile phones using deep learning technique. (n.d.-d). https://www.researchgate.net/publication/343290099_Detecting_Usage_of_Mobile_Phones_using_Deep_Learning_Technique\n",
    "\n",
    " IEEE Xplore Full-text PDF: (n.d.-e). https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7169508 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1b351",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c8dd0",
   "metadata": {},
   "source": [
    "For this project, we are working with two comprehensive datasets to develop and evaluate our cell phone detection model: the COCO 2017 dataset and the Open Images V6 dataset.\n",
    "\n",
    "The COCO (Common Objects in Context) 2017 dataset is a cornerstone in computer vision research. It comprises 118,000 training images and 5,000 validation images, covering a diverse range of real-world scenes. Each image is meticulously annotated with bounding boxes and masks, encompassing 80 distinct object categories. Moreover, the dataset includes human-generated captions, making it versatile for tasks such as image captioning and multimodal learning. The COCO dataset is well-regarded as a benchmark for object detection, segmentation, and captioning, providing us with a robust foundation for evaluating and fine-tuning our cell phone detection model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d224c72",
   "metadata": {},
   "source": [
    "<img src=\"images\\2.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ebdeb",
   "metadata": {},
   "source": [
    "The Open Images V6 dataset serves as another invaluable resource, boasting an impressive collection of 9 million images featuring diverse real-world scenes and objects. This dataset stands out with its annotation details, encompassing 36 million image-level labels, 15.8 million bounding boxes for precise object localization, and 2.8 million instance segmentations for fine-grained object analysis. The inclusion of the Open Images Challenges further contributes to driving advancements in object detection, segmentation, and visual relationship detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b5718",
   "metadata": {},
   "source": [
    "<img src=\"images\\3.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9078e",
   "metadata": {},
   "source": [
    "To prepare these datasets for our cell phone detection project, we performed preprocessing to extract the relevant data and annotations related to cell phones. This involved filtering the datasets to isolate images containing cell phones and ensuring accurate bounding box annotations. Additionally, we curated the data to create a balanced and representative subset for our specific task. These preprocessing steps were crucial in enabling us to focus our model training on cell phone detection while leveraging the rich annotations and diverse scenes provided by these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65b366",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ca94f",
   "metadata": {},
   "source": [
    "Our approach to solving the cell phone detection problem involves the utilization of both established and cutting-edge object detection models: Single Shot MultiBox Detector (SSD) and Faster R-CNN, along with the state-of-the-art You Only Look Once (YOLO) version 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18eeb35",
   "metadata": {},
   "source": [
    "#### TensorFlow API for SSD and Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87309d52",
   "metadata": {},
   "source": [
    "We leveraged the TensorFlow Object Detection API to implement and fine-tune SSD and Faster R-CNN models. These models are well-established in the field of object detection and have demonstrated their effectiveness in various applications. We configured the models to detect cell phones based on the annotated bounding box data from the COCO 2017 dataset. Our choice of these models stems from their proven track record, and their complex architectures are designed to handle diverse scenarios effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9beba87",
   "metadata": {},
   "source": [
    "#### YOLO-v8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90350b7d",
   "metadata": {},
   "source": [
    "We also employed YOLO-v8, the latest iteration of the YOLO framework, renowned for its real-time capabilities and accuracy. YOLO's unique approach of dividing the input image into a grid and predicting bounding boxes and class probabilities directly in one pass aligns well with our objective of fast and efficient cell phone detection. YOLO-v8 has been fine-tuned specifically for cell phone detection using transfer learning and a dataset curated from the COCO 2017 and Open Images V6 datasets. The model's architecture and real-time performance make it a compelling choice for our application.\n",
    "\n",
    "Our selection of these models is based on their compatibility with the problem and their demonstrated success in object detection tasks. The TensorFlow API provided a streamlined implementation process for SSD and Faster R-CNN, while YOLO-v8's inherent real-time capabilities and performance advantages make it an appealing option for our cell phone detection goal.\n",
    "\n",
    "In the course of our work, we have applied concepts and techniques learned, such as data preprocessing, model selection, transfer learning, and performance evaluation. These methods collectively contribute to our comprehensive approach, enabling us to address the challenge of accurate and efficient cell phone detection in real-world images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a00123",
   "metadata": {},
   "source": [
    "### Experimental Analysis: Evaluating Cell Phone Detection Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded1f72",
   "metadata": {},
   "source": [
    "In our pursuit to demonstrate the effectiveness of our approach for cell phone detection, we performed a series of experiments involving the TensorFlow API for SSD and Faster R-CNN, as well as YOLOv8 with the assistance of Ultralytics and FiftyOne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3d186",
   "metadata": {},
   "source": [
    "#### TensorFlow API for SSD and Faster R-CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebbbda",
   "metadata": {},
   "source": [
    "We first implemented and evaluated SSD and Faster R-CNN models using the TensorFlow Object Detection API. These models were trained on the COCO 2017 dataset with annotations specific to cell phone detection. We compared their performance in terms of real-time detection capabilities and accurate localization. The TensorFlow API streamlined our implementation, allowing rapid prototyping, extensibility, and benefiting from community support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709d80a",
   "metadata": {},
   "source": [
    "#### YOLOv8 with Ultralytics and FiftyOne:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c0b3c",
   "metadata": {},
   "source": [
    "To harness the capabilities of YOLOv8, we employed Ultralytics and FiftyOne, which significantly enhanced our YOLOv8-based experiments. Ultralytics, an open-source library, facilitated model training, inference, and evaluation for YOLOv8. FiftyOne, an advanced data visualization tool, improved model interpretation and dataset analysis, enabling us to gain deeper insights into our YOLOv8-based cell phone detection model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d97064",
   "metadata": {},
   "source": [
    "<img src=\"images\\4.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5832111",
   "metadata": {},
   "source": [
    "<img src=\"images\\5.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe8bdf",
   "metadata": {},
   "source": [
    "#### YOLOv8 Base Version - Cell Phone Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79997e39",
   "metadata": {},
   "source": [
    "To quantitatively assess the performance of YOLOv8, we introduced the concept of the \"Cell Phone Matrix.\" This matrix provided a clear representation of the model's performance in detecting cell phones. It included metrics such as True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN), allowing us to interpret the model's performance accurately. This matrix served as a guide for evaluating and refining the performance of the YOLOv8 base version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69062b18",
   "metadata": {},
   "source": [
    "<img src=\"images\\6.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50ad76",
   "metadata": {},
   "source": [
    "#### YOLOv8 Fine-Tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db3e8e",
   "metadata": {},
   "source": [
    "In our efforts to enhance the model's performance, we undertook a fine-tuning process for YOLOv8. We combined datasets from COCO 2017 and Google Open Images, creating a comprehensive training set. Through iterative optimization, we fine-tuned the YOLOv8 model specifically for cell phone detection. This fine-tuning process aimed to improve the model's accuracy and efficiency in identifying cell phones within complex real-world images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa2266",
   "metadata": {},
   "source": [
    "<img src=\"images\\7.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe7a64",
   "metadata": {},
   "source": [
    "<img src=\"images\\8.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5387cb",
   "metadata": {},
   "source": [
    "Through these experiments, we aimed to demonstrate the efficacy of our approach in solving the cell phone detection problem. Our experiments spanned from model selection and performance evaluation to advanced visualization tools and fine-tuning strategies. The results of these experiments provide valuable insights into the strengths and limitations of our approach and pave the way for the development of a robust and efficient cell phone detection system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918baba7",
   "metadata": {},
   "source": [
    "### Map Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64d480",
   "metadata": {},
   "source": [
    "#### Fine-Tuned Model: Enhancing Cell Phone Detection through Iterative Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee50d1",
   "metadata": {},
   "source": [
    "The detection of cell phones in real-world images is a critical task with applications ranging from security to user experience enhancement. To address this challenge, we embarked on a journey to develop an accurate and efficient cell phone detection model. Leveraging the You Only Look Once (YOLO) framework, we conducted fine-tuning experiments to enhance the model's performance, generalization, and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5781d89",
   "metadata": {},
   "source": [
    "#### Benefits of Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5171a",
   "metadata": {},
   "source": [
    "Fine-tuning our model presented several advantages. By incorporating data from diverse sources such as the COCO 2017 and Google Open Images datasets, we aimed to enrich our model's understanding of cell phone characteristics in different contexts. This increased data diversity contributed to improved generalization, allowing the model to perform well in various scenarios beyond its original training data. Additionally, fine-tuning enhanced the model's robustness by fine-tuning its parameters to better capture the intricacies of cell phone detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c419638",
   "metadata": {},
   "source": [
    "#### Fine-Tuned Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b67a00",
   "metadata": {},
   "source": [
    "Upon fine-tuning our model, we observed promising results. The model exhibited improved accuracy and better performance on cell phone detection tasks compared to its base version. However, we recognize that achieving optimal performance is an iterative process. Our ongoing research involves a meticulous analysis of the Cell Phone Matrix, a representation of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) in cell phone detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68286bef",
   "metadata": {},
   "source": [
    "#### Iterative Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a912bb5",
   "metadata": {},
   "source": [
    "Our current focus lies in the analysis of the Cell Phone Matrix. By dissecting the matrix, we identify areas for further improvement. Iterative fine-tuning of the model allows us to systematically address shortcomings, optimize hyperparameters, and enhance model precision. The iterative approach ensures that our model evolves progressively, inching closer to a state of high accuracy and real-time performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa34115",
   "metadata": {},
   "source": [
    "<img src=\"images\\9.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc04ee",
   "metadata": {},
   "source": [
    "### Conclusion and Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197334c",
   "metadata": {},
   "source": [
    "In this endeavor, we have successfully fine-tuned a YOLO-based cell phone detection model, elevating its performance and robustness. The iterative fine-tuning process, guided by the analysis of the Cell Phone Matrix, provides a roadmap for continual improvement. Our commitment to ongoing research and refinement underscores our dedication to developing an accurate and efficient solution for cell phone detection.\n",
    "\n",
    "As we move forward, we remain dedicated to furthering our understanding of the intricacies of cell phone detection and iteratively refining our model. Through continuous analysis, optimization, and experimentation, we strive to contribute to the advancements in computer vision technology, with practical applications in security, surveillance, and user experience enhancement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda6d0f",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a595cf",
   "metadata": {},
   "source": [
    "Through our experiments and exploration of various object detection algorithms, we have achieved significant insights and results in the field of cell phone detection. We successfully implemented and evaluated the TensorFlow API for SSD and Faster R-CNN, showcasing their strengths in real-time detection and accurate localization. Additionally, we harnessed the power of YOLOv8 with the assistance of Ultralytics and FiftyOne, optimizing its performance and enhancing our understanding of its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c0efe",
   "metadata": {},
   "source": [
    "### Key Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820a62a",
   "metadata": {},
   "source": [
    "- **Algorithm Comparison**:  We gained a deeper understanding of the strengths and weaknesses of different object detection algorithms, including their trade-offs between real-time capabilities and precise localization.\n",
    "\n",
    "- **Fine-Tuning and Optimization**:  Our fine-tuning process demonstrated the potential of combining datasets and iteratively optimizing models to achieve better performance for specific tasks.\n",
    "\n",
    "- **Visualization and Interpretation**: The introduction of the Cell Phone Matrix provided a clear way to interpret model outcomes, aiding in the assessment of cell phone detection performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8fe02b",
   "metadata": {},
   "source": [
    "### Future Extensions and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccc48b",
   "metadata": {},
   "source": [
    "- **Ensemble Methods**: Future work could involve exploring ensemble methods that combine the strengths of different object detection algorithms, potentially leading to even more accurate and robust cell phone detection systems.\n",
    "\n",
    "- **Multimodal Detection**:  Expanding the scope to multimodal detection, such as detecting cell phones in videos or alongside other objects, could provide valuable insights for security and surveillance applications.\n",
    "\n",
    "- **Adaptive Learning**:  Developing adaptive learning approaches that allow the model to continuously improve its performance based on real-world feedback could lead to more reliable and adaptable cell phone detection systems.\n",
    "\n",
    "- **Privacy Preservation**:  Investigating techniques to detect and redact sensitive information on detected cell phones, ensuring privacy in surveillance scenarios, is a critical avenue for future research.\n",
    "\n",
    "- **Real-World Deployment**: Moving beyond experimentation, deploying the cell phone detection model in real-world scenarios and evaluating its performance in practical applications could validate its effectiveness and provide invaluable feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d8a23",
   "metadata": {},
   "source": [
    "<img src=\"images\\10.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b0abb",
   "metadata": {},
   "source": [
    "<img src=\"images\\11.jpg\" width = 650 height = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746193d",
   "metadata": {},
   "source": [
    "In conclusion, our project has successfully contributed to the advancement of cell phone detection technology through a combination of established and cutting-edge techniques. The key insights gained from our experiments and the potential future extensions of our work underscore the significance and ongoing potential of our research. For a more detailed report, including our latest deployment using Hugging Face Spaces and Gradio, please refer to the provided link:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb0c3c",
   "metadata": {},
   "source": [
    "https://huggingface.co/spaces/Dush91/cellphone-detector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
